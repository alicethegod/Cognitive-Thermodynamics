{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Final Data Processing and Plotting Script for Cognitive Thermodynamics\n",
        "\n",
        "This script serves as the final, definitive analysis tool for our research. It\n",
        "separates the data analysis from the raw experiment generation, which is a key\n",
        "scientific best practice.\n",
        "\n",
        "It performs the following critical steps:\n",
        "1.  **Loads Raw Data**: It loads the results JSON file from a path specified\n",
        "    via a command-line argument, making the script portable.\n",
        "2.  **Normalization**: It normalizes H_TSE' and H_SIE' to a comparable range.\n",
        "3.  **Calculates Weighted Load**: It computes the \"Total Cognitive Load\" norm.\n",
        "4.  **Generates Publication-Ready Plots**: It creates the main and supplementary\n",
        "    plots for the paper, with polished legends and labels for maximum clarity.\n",
        "\"\"\"\n",
        "import json\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "from scipy.stats import linregress\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import argparse\n",
        "\n",
        "def load_results(file_path):\n",
        "    \"\"\"Loads results from the specified JSON file.\"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as f:\n",
        "            return json.load(f)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Results file not found at the specified path: {file_path}\")\n",
        "        return None\n",
        "    except json.JSONDecodeError:\n",
        "        print(f\"Error: Could not decode JSON from the file: {file_path}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "def process_data(results):\n",
        "    \"\"\"Normalizes data and calculates the weighted cognitive load.\"\"\"\n",
        "    if not results:\n",
        "        return {}\n",
        "\n",
        "    # DEBUG: Handle scalar and list-of-list data separately for robustness.\n",
        "    # Process scalar values into numpy arrays\n",
        "    scalar_keys = [k for k in results[0].keys() if k != 'energy_distribution']\n",
        "    data = {key: np.array([r.get(key, 0) for r in results]) for key in scalar_keys}\n",
        "\n",
        "    # Handle the list of lists 'energy_distribution' separately to preserve its structure\n",
        "    if 'energy_distribution' in results[0]:\n",
        "        data['energy_distribution'] = [r.get('energy_distribution', []) for r in results]\n",
        "\n",
        "    # Initialize scalers\n",
        "    htse_scaler = MinMaxScaler()\n",
        "    hsie_scaler = MinMaxScaler()\n",
        "\n",
        "    # Reshape for scaler and fit_transform\n",
        "    data['htse_norm'] = htse_scaler.fit_transform(data['htse'].reshape(-1, 1)).flatten()\n",
        "    data['hsie_norm'] = hsie_scaler.fit_transform(data['hsie'].reshape(-1, 1)).flatten()\n",
        "\n",
        "    # Calculate the weighted norm (Total Cognitive Load)\n",
        "    w1, w2 = 0.5, 0.5\n",
        "    data['cognitive_load_norm'] = np.sqrt(\n",
        "        (w1 * data['htse_norm'])**2 + (w2 * data['hsie_norm'])**2\n",
        "    )\n",
        "\n",
        "    return data\n",
        "\n",
        "def plot_definitive_results(data, output_dir=\".\"):\n",
        "    \"\"\"Generates the final 2x3 'six-act narrative' plot for the paper.\"\"\"\n",
        "    if not data:\n",
        "        print(\"No data to plot for definitive results.\")\n",
        "        return\n",
        "\n",
        "    gens = data['generation']\n",
        "\n",
        "    plt.style.use('seaborn-v0_8-whitegrid')\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(24, 13)) # Increased height slightly\n",
        "    fig.suptitle('Definitive Experiment: The Thermodynamic Collapse of a Closed Cognitive System', fontsize=24, y=0.98)\n",
        "\n",
        "    # Plot 1: Performance Degradation\n",
        "    axes[0, 0].plot(gens, data['accuracy'], marker='o', c='r')\n",
        "    axes[0, 0].set_title('1. Informational Collapse', fontsize=16)\n",
        "    axes[0, 0].set_ylabel('Accuracy on Real Test Set (%)', fontsize=14)\n",
        "\n",
        "    # Plot 2: System Temperature (ICE)\n",
        "    axes[0, 1].plot(gens, data['inter_conceptual_entropy'], marker='x', c='darkred')\n",
        "    axes[0, 1].set_title('2. Semantic Heat Death (ICE)', fontsize=16)\n",
        "    axes[0, 1].set_ylabel('System Temperature (Entropy)', fontsize=14)\n",
        "\n",
        "    # Plot 3: Organizational Collapse (SO)\n",
        "    axes[0, 2].plot(gens, data['so'], marker='d', c='purple', alpha=0.6, label='Raw SO')\n",
        "    so_smooth = sm.nonparametric.lowess(data['so'], gens, frac=0.4)[:, 1]\n",
        "    axes[0, 2].plot(gens, so_smooth, c='indigo', lw=2.5, label='SO Trend (LOWESS)')\n",
        "    axes[0, 2].set_title('3. Organizational Collapse (SO)', fontsize=16)\n",
        "    axes[0, 2].set_ylabel('Avg. Specialization Similarity', fontsize=14)\n",
        "    axes[0, 2].legend(loc='lower right', fontsize='small')\n",
        "\n",
        "    # Plot 4: The Entropy Trade-off (Normalized)\n",
        "    axes[1, 0].plot(gens, data['htse_norm'], marker='s', ls='--', c='b', alpha=0.7, label=\"H_TSE' (Normalized)\")\n",
        "    axes[1, 0].plot(gens, data['hsie_norm'], marker='^', ls=':', c='g', alpha=0.7, label=\"H_SIE' (Normalized)\")\n",
        "    axes[1, 0].set_title(\"4. The Entropy Trade-off (Normalized)\", fontsize=16)\n",
        "    axes[1, 0].set_ylabel(\"Normalized Entropy Value\", fontsize=14)\n",
        "    axes[1, 0].legend(loc='upper right', fontsize='small')\n",
        "\n",
        "    # Plot 5: Statistical Proof of Collapse (for Normalized Total Cognitive Load)\n",
        "    latter_half_idx = len(gens) // 2\n",
        "    if latter_half_idx > 1:\n",
        "        loads_smooth = sm.nonparametric.lowess(data['cognitive_load_norm'], gens, frac=0.4)[:, 1]\n",
        "        slope, intercept, _, p_value, _ = linregress(gens[latter_half_idx:], loads_smooth[latter_half_idx:])\n",
        "\n",
        "        axes[1, 1].scatter(gens, data['cognitive_load_norm'], c='purple', alpha=0.2, label='Raw Normalized Load')\n",
        "        axes[1, 1].plot(gens, loads_smooth, c='indigo', lw=2.5, label='Smoothed Trend')\n",
        "        axes[1, 1].plot(gens[latter_half_idx:], intercept + slope*gens[latter_half_idx:], 'r', lw=2, label='Linear Fit on Trend')\n",
        "        axes[1, 1].set_title(\"5. Statistical Proof: The Second Law\", fontsize=16)\n",
        "        axes[1, 1].legend(loc='lower right', fontsize='small')\n",
        "        result_text = f\"Trend Analysis (Gens {latter_half_idx}-{len(gens)-1}):\\nSlope = {slope:+.5f}\\np-value = {p_value:.4f}\"\n",
        "        if p_value < 0.05:\n",
        "            result_text += \"\\n(Statistically Significant)\"\n",
        "            axes[1, 1].set_facecolor('#e6ffe6')\n",
        "        else:\n",
        "            result_text += \"\\n(Not Significant)\"\n",
        "            axes[1, 1].set_facecolor('#ffe6e6')\n",
        "\n",
        "        axes[1, 1].text(0.05, 0.95, result_text, transform=axes[1, 1].transAxes, fontsize=11,\n",
        "                       verticalalignment='top', bbox=dict(boxstyle='round,pad=0.5', fc='wheat', alpha=0.7))\n",
        "\n",
        "    # Plot 6: Cognitive Energy Distribution\n",
        "    if 'energy_distribution' in data and len(data['energy_distribution']) > 0:\n",
        "        # The data processing function now ensures this is a clean list of lists\n",
        "        energy_data = [np.array(item) for item in data['energy_distribution'] if isinstance(item, list) and len(item) > 0]\n",
        "        if len(energy_data) >= 2:\n",
        "            energy_gen0, energy_gen_final = energy_data[0], energy_data[-1]\n",
        "            if energy_gen0.size > 0 and energy_gen_final.size > 0:\n",
        "                axes[1, 2].hist(energy_gen0, bins=20, alpha=0.7, label=f'Healthy State (Gen 0)', color='blue', density=True)\n",
        "                axes[1, 2].hist(energy_gen_final, bins=20, alpha=0.7, label=f'Collapsed State (Gen {len(gens)-1})', color='red', density=True)\n",
        "                axes[1, 2].set_yscale('log')\n",
        "                axes[1, 2].legend(fontsize='small')\n",
        "    axes[1, 2].set_title('6. Cognitive Energy Distribution', fontsize=16)\n",
        "    axes[1, 2].set_xlabel(\"Cognitive Energy Level (E_cog)\", fontsize=14)\n",
        "    axes[1, 2].set_ylabel(\"Probability Density\", fontsize=14)\n",
        "\n",
        "    for ax in axes.flat:\n",
        "        if ax != axes[1, 2]:\n",
        "            ax.set_xlabel('Generation', fontsize=14)\n",
        "        ax.grid(True, which=\"both\", ls=\"--\")\n",
        "        ax.tick_params(axis='both', which='major', labelsize=12)\n",
        "    axes[1, 1].set_ylabel(\"Total Cognitive Load (Normalized Norm)\", fontsize=14)\n",
        "\n",
        "    plt.subplots_adjust(left=0.05, right=0.98, top=0.9, bottom=0.08, hspace=0.3, wspace=0.25)\n",
        "\n",
        "    plot_path = os.path.join(output_dir, \"definitive_main_plot.png\")\n",
        "    plt.savefig(plot_path, dpi=300)\n",
        "    print(f\"\\nMain narrative plot saved to: {plot_path}\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def plot_supplementary_results(data, output_dir=\".\"):\n",
        "    \"\"\"Generates the supplementary plot with detailed statistical analyses.\"\"\"\n",
        "    if not data or 'so' not in data:\n",
        "        print(\"Skipping supplementary plots due to missing data ('so').\")\n",
        "        return\n",
        "\n",
        "    gens = data['generation']\n",
        "    htses = data['htse']\n",
        "    hsies = data['hsie']\n",
        "    sos = data['so']\n",
        "\n",
        "    cces = data.get('cce', np.zeros_like(gens))\n",
        "    if len(cces) != len(gens): cces = np.zeros_like(gens)\n",
        "\n",
        "    plt.style.use('seaborn-v0_8-whitegrid')\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    fig.suptitle('Supplementary Material: Detailed Statistical Analysis of Key Metrics', fontsize=20, y=0.98)\n",
        "\n",
        "    latter_half_idx = len(gens) // 2\n",
        "    if latter_half_idx <= 1:\n",
        "        print(\"Not enough data points for trend analysis.\")\n",
        "        return\n",
        "\n",
        "    # Supp 1: H_TSE' Trend Analysis\n",
        "    htse_smooth = sm.nonparametric.lowess(htses, gens, frac=0.4)[:, 1]\n",
        "    slope_tse, _, _, p_tse, _ = linregress(gens[latter_half_idx:], htse_smooth[latter_half_idx:])\n",
        "    axes[0, 0].scatter(gens, htses, alpha=0.3, label='Raw Data');\n",
        "    axes[0, 0].plot(gens, htse_smooth, color='navy', lw=2.5, label='Smoothed Trend')\n",
        "    axes[0, 0].set_title(f\"H_TSE' Trend (p={p_tse:.3f})\", fontsize=14);\n",
        "    axes[0, 0].set_ylabel(\"Grounding Cost (H_TSE')\", fontsize=12);\n",
        "    axes[0, 0].legend(loc='best', fontsize='small')\n",
        "\n",
        "    # Supp 2: H_SIE' Trend Analysis\n",
        "    hsie_smooth = sm.nonparametric.lowess(hsies, gens, frac=0.4)[:, 1]\n",
        "    slope_sie, _, _, p_sie, _ = linregress(gens[latter_half_idx:], hsie_smooth[latter_half_idx:])\n",
        "    axes[0, 1].scatter(gens, hsies, alpha=0.3, color='g', label='Raw Data');\n",
        "    axes[0, 1].plot(gens, hsie_smooth, color='darkgreen', lw=2.5, label='Smoothed Trend')\n",
        "    axes[0, 1].set_title(f\"H_SIE' Trend (p={p_sie:.3f})\", fontsize=14);\n",
        "    axes[0, 1].set_ylabel(\"Structural Complexity (H_SIE')\", fontsize=12);\n",
        "    axes[0, 1].legend(loc='best', fontsize='small')\n",
        "\n",
        "    # Supp 3: SO Trend Analysis\n",
        "    so_smooth = sm.nonparametric.lowess(sos, gens, frac=0.4)[:, 1]\n",
        "    slope_so, _, _, p_so, _ = linregress(gens[latter_half_idx:], so_smooth[latter_half_idx:])\n",
        "    axes[1, 0].scatter(gens, sos, alpha=0.3, color='purple', label='Raw Data');\n",
        "    axes[1, 0].plot(gens, so_smooth, color='indigo', lw=2.5, label='Smoothed Trend')\n",
        "    axes[1, 0].set_title(f\"SO Trend (p={p_so:.3f})\", fontsize=14);\n",
        "    axes[1, 0].set_ylabel(\"Organizational Collapse (SO)\", fontsize=12);\n",
        "    axes[1, 0].legend(loc='best', fontsize='small')\n",
        "\n",
        "    # Supp 4: CCE Trend Analysis\n",
        "    if 'cce' in data and len(data['cce']) == len(gens) and np.any(cces):\n",
        "        cce_smooth = sm.nonparametric.lowess(cces, gens, frac=0.4)[:, 1]\n",
        "        slope_cce, _, _, p_cce, _ = linregress(gens[latter_half_idx:], cce_smooth[latter_half_idx:])\n",
        "        axes[1, 1].scatter(gens, cces, alpha=0.3, color='teal', label='Raw Data');\n",
        "        axes[1, 1].plot(gens, cce_smooth, color='darkcyan', lw=2.5, label='Smoothed Trend')\n",
        "        axes[1, 1].set_title(f\"CCE Trend (p={p_cce:.3f})\", fontsize=14);\n",
        "        axes[1, 1].set_ylabel(\"Avg. Neuron Specialization (CCE)\", fontsize=12);\n",
        "        axes[1, 1].legend(loc='best', fontsize='small')\n",
        "    else:\n",
        "        axes[1, 1].text(0.5, 0.5, \"CCE data not available\\nor all zeros.\", ha='center', va='center')\n",
        "        axes[1, 1].set_title(\"CCE Trend\", fontsize=14)\n",
        "\n",
        "\n",
        "    for ax in axes.flat:\n",
        "        ax.set_xlabel('Generation', fontsize=12)\n",
        "        ax.grid(True, which=\"both\", ls=\"--\")\n",
        "        ax.tick_params(axis='both', which='major', labelsize=10)\n",
        "\n",
        "    plt.subplots_adjust(left=0.07, right=0.97, top=0.9, bottom=0.08, hspace=0.3, wspace=0.3)\n",
        "\n",
        "    plot_path_supp = os.path.join(output_dir, \"supplementary_plots.png\")\n",
        "    plt.savefig(plot_path_supp, dpi=300)\n",
        "    print(f\"Supplementary plots saved to: {plot_path_supp}\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser(description='Process and plot the results of the Cognitive Thermodynamics experiment.')\n",
        "    parser.add_argument('--json_path', type=str, required=True,\n",
        "                        help='The full path to the results JSON file (e.g., \"results_sgd_focused/sgd_focused_results.json\").')\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    raw_results = load_results(args.json_path)\n",
        "    if raw_results:\n",
        "        if isinstance(raw_results, dict):\n",
        "            print(\"Multiple runs detected in JSON, analyzing the first one found.\")\n",
        "            for key in raw_results:\n",
        "                if isinstance(raw_results[key], list) and len(raw_results[key]) > 0:\n",
        "                    processed_data = process_data(raw_results[key])\n",
        "                    break\n",
        "        else:\n",
        "            processed_data = process_data(raw_results)\n",
        "\n",
        "        output_folder = \"final_analysis\"\n",
        "        os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "        plot_definitive_results(processed_data, output_dir=output_folder)\n",
        "        plot_supplementary_results(processed_data, output_dir=output_folder)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "4NJV1oyVZquq"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
